\documentclass{INTERSPEECH2023}

% **************************************
% *    DOUBLE-BLIND REVIEW SETTINGS    *
% **************************************
% Comment out \interspeechcameraready when submitting the 
% paper for review.
% If your paper is accepted, uncomment this to produce the
%  'camera ready' version to submit for publication.
\interspeechcameraready 

% imports
\usepackage[acronym,toc,shortcuts,nonumberlist]{glossaries}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{xcolor}

\input{acronyms}
\input{commands}

\title{Comparative Analysis of the wav2vec 2.0 Feature Extractor}
\name{Peter Vieting$^{1}$, Ralf Schl\"uter$^{1,2}$, Hermann Ney$^{1,2}$}
\address{
  $^1$RWTH Aachen University, Germany\\
  $^2$AppTek GmbH, Germany}
\email{\{vieting,schlueter,ney\}@cs.rwth-aachen.de}

\begin{document}

\maketitle
 
\begin{abstract}
Raw waveform modeling is an interesting research topic for \gls{ASR}.
\wvtwo has seen large success recently and makes use of a convolutional \fe which operates directly on the speech waveform.
Typically, this \fe is seen as part of the overall architecture, but this work investigates this component specifically.
It is used as a replacement for classical feature extraction methods in a \gls{CTC} setup and compared to an alternative neural \fe approach.
Finally, we analyze the learned representations of both neural \fes.
\end{abstract}
\noindent\textbf{Index Terms}: speech recognition, feature extraction, raw waveform modeling


\section{Introduction}
\draft{
Why is raw waveform modeling interesting?

\wvtwo is very successful and uses neural \fe.

Comparable to other neural feature extraction methods, but not closely studied in the literature.
Maybe some references or name some works which are similar.

Highlight contributions of this paper.
}

\section{Related work}
\draft{
Works on raw waveform acoustic modeling.
Think about how to properly reference \cite{vieting2021waveform} without disclosing author information.

Different \wv papers \cite{facebook2019wav2vec, facebook2019vqwav2vec, facebook2020wav2vec2, facebook2020xlsr}.
Describe differences between the approaches.
Besides modifications of the self-supervised training criteria -- moving from the future time step prediction in \cite{facebook2019wav2vec} to masked time step prediction -- and incorporating quantization modules, also the architecture has been revised.
Fully convolutional vs. \transformer.
Differences in \fe.

\cite{facebook2019wav2vec} uses 5 layers with kernel sizes (10, 8, 4, 4, 4) and strides which are always exactly half the kernel size.
All have 512 channels, a group normalization layer with a single group and a \relu nonlinearity.
\cite{facebook2020wav2vec2} uses seven layers with kernel sizes (10, 3, 3, 3, 3, 2, 2), strides (5, 2, 2, 2, 2, 2, 2), and a GELU activation function.
The first layer applies group normalization and finally, layer normalization and a linear projection is added.
}

\section{Methods}
We always normalize the waveform to zero mean and unit variance.
Then, it is input to a \fe.
The \fe is followed by the remaining \gls{AM}.
While the separation between \fe and remaining \gls{AM} is not sharp for neural feature extraction, we always refer to the part that replaces the traditional feature extraction as \fe.

\subsection{Feature Extractors}
\subsubsection{Standard Feature Extraction}
As a reference, we use standard, hand-designed \fes -- namely log Mel filterbank features and Gammatone features.
To compute the log Mel filterbank features, first the \gls{STFT} of the waveform is computed with a window size of \SI{25}{\milli\second} and a shift of \SI{10}{\milli\second}.
We keep the square of the magnitude and perform Mel warping to obtain a 80-dim vector.
Finally, $\log_{10}$ and normalization are applied.

Gammatone features apply a gammatone filterbank to the pre-emphasized speech signal, perform temporal integration over each channel using a low pass filter, i.e., the Hanning window with a size of \SI{25}{\milli\second} and a shift of \SI{10}{\milli\second}, compress using the $10^{th}$ root and finally compute the \gls{DCT} of the values \cite{schlueter:icassp07}.
Further, the the resulting 50-dim features are normalized.

\subsubsection{\wvtwo Feature Extractor}
The \gls{FE} of the \wvtwo model \cite{facebook2020wav2vec2}.

\subsubsection{Supervised Convolutional Features}
As an alternative comparable neural feature extraction method, we use \gls{SCF} \cite{tuske2018:waveform}.
Similarly, a convolutional filterbank with learnable parameters is applied to the waveform.
As in the case of Gammatones, a temporal integration is performed over each channel.
However, in this case multiple filters are used for temporal integration allowing for multi-resolutional processing.
Additionally, these filters are learned during training.
We set the size of the first filterbank to 256, its strides to 10 and the number of channels to 150.
The second convolutional filter applies 5 temporal integration filters with a size of 40 and strides of 16 each.
Since the output of all 5 filters is stacked, we have a resulting feature dimension of 750.

\section{Experiments}
\subsection{Model Sizes}
By default, I use 40k parameters for i6 features compared to 4M for \wvtwo.
Can we improve the performance by making the model larger?
\subsubsection{wav2vec 2.0 Components}
To understand where \wvtwo uses the parameters and how much they contribute to the \gls{FE}'s performance, we run it with different configurations.
The results for different widths and depths are shown in \refTab{table:features_w2v_size}.
% Kernel sizes and strides were chosen as (10, 3, 3, 3, 3, 2), (5, 2, 2, 2, 2, 2) for 6 layers, (10, 6, 3, 3, 3), (5, 4, 2, 2, 2) for 5 layers, (10, 6, 6, 3), (5, 4, 4, 2) for 4 layers, (20, 6, 6), (10, 4, 4) for 3 layers, (32, 20), (16, 10) for 2 layers and (320), (160) for 1 layer.
While a larger inner dimension leads to a better performance, no major effect can be observed regarding the number of layers.
The final projection additionally improves the performance, see \refTab{table:features_w2v_proj}.
We can additionally vary the kernel size and final norm.

\subsubsection{Inner Dimensions}
As a larger inner dimension clearly showed better performance for the \wvtwo \gls{FE}, we increase the inner dimensions of the i6 features as well.
However, as shown in \refTab{table:features_i6_size}, neither increasing the inner dimension of the first layer nor the second layer helps to improve the performance.

\subsubsection{First Layer Window Size}
What role does the size of the first layer play? Is it important to cover one pitch period (max. fundamental period)?
By default, I use a window size of \SI{16}{\milli\second}.
Experiments on using different window sizes in \refTab{table:features_window_size} suggest that a larger window size has a detrimental effect while going from the default \SI{16}{\milli\second} down to \SI{10}{\milli\second} shows a marginal improvement.

\section{Results}
The results for the different feature extractors used with a competitive \gls{CTC} model on Librispeech are shown in \refTab{table:features_general}.
\input{tables/features_general}

\subsection{Model Sizes}
Results are in the following tables.
\input{tables/features_w2v_size}
\input{tables/features_w2v_proj}
\input{tables/features_i6_size}
\input{tables/features_window_size}

\subsection{\wvtwo Pre-Training}
\input{tables/features_pretraining}

\section{Conclusions}

\section{Acknowledgements}

\ifinterspeechfinal
     Personal information revealing author identity
\else
     Anonymized information not revealing author identity
\fi

\section{To Dos/Questions}
\begin{itemize}
  \item \wvtwo feature extractor vs. feature encoder
\end{itemize}

\bibliographystyle{IEEEtran}
\bibliography{mybib}

\end{document}
